{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import gc\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_features(length, periods=[24, 168, 720]):\n",
    "    \"\"\"\n",
    "    Generate sinusoidal time features with multiple periodicities.\n",
    "    \n",
    "    Args:\n",
    "        length: Number of time steps\n",
    "        periods: List of period values for sinusoidal encoding\n",
    "        \n",
    "    Returns:\n",
    "        Array of shape (length, 2*len(periods)+1) containing:\n",
    "        - sin/cos pairs for each period\n",
    "        - normalized time progress\n",
    "        \n",
    "    Note: For satellite channels, you may want to adjust periods based on\n",
    "    orbital dynamics. Current defaults (24, 168, 720) are suitable for\n",
    "    phenomena with daily/weekly patterns.\n",
    "    \"\"\"\n",
    "    i = np.arange(length, dtype=np.float32)\n",
    "    \n",
    "    features = []\n",
    "    for period in periods:\n",
    "        angle = 2 * np.pi * i / period\n",
    "        features.append(np.sin(angle).astype(np.float32))\n",
    "        features.append(np.cos(angle).astype(np.float32))\n",
    "    \n",
    "    # Add normalized time index for sequence progression\n",
    "    time_progress = (i / length).astype(np.float32)\n",
    "    features.append(time_progress)\n",
    "    \n",
    "    return np.column_stack(features)  # Shape: (length, 2*len(periods)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for single-variable time series with channel ageing.\n",
    "    \n",
    "    The dataset creates training samples where:\n",
    "    - Input window: CSI from t-P-A+1 to t-A (P historical steps)\n",
    "    - Target: CSI from t-G-A+1+A to t-G-A+F+A (F future steps after delay A)\n",
    "    \n",
    "    Args:\n",
    "        raw_data: 1D array of channel measurements\n",
    "        P: Number of historical steps (input sequence length)\n",
    "        G: Number of recent steps used by decoder\n",
    "        F: Number of future steps to predict\n",
    "        A: Aging delay (time steps)\n",
    "        mean/std: Normalization parameters (computed from training set)\n",
    "        start_idx/end_idx: Data slice for train/val/test split\n",
    "    \"\"\"\n",
    "    def __init__(self, raw_data, P, G, F, A,\n",
    "                 mean=None, std=None, \n",
    "                 start_idx=None, end_idx=None):\n",
    "        self.P = P\n",
    "        self.G = G\n",
    "        self.F = F\n",
    "        self.A = A\n",
    "        \n",
    "        # Convert to float32 and slice\n",
    "        raw_data = raw_data.astype(np.float32)\n",
    "        self.raw_data = raw_data[start_idx:end_idx]\n",
    "        \n",
    "        # Compute normalization statistics\n",
    "        self.mean = mean if mean is not None else self.raw_data.mean()\n",
    "        self.std = std if std is not None else self.raw_data.std()\n",
    "        \n",
    "        # Normalize data\n",
    "        self.data = ((self.raw_data - self.mean) / (self.std + 1e-8)).astype(np.float32)\n",
    "        \n",
    "        # Generate time features (7 features: 3 periods × 2 + time progress)\n",
    "        self.time_features = generate_time_features(len(self.raw_data)).astype(np.float32)\n",
    "        \n",
    "        # Combine: [normalized_value, time_features] → shape (T, 8)\n",
    "        self.features = np.hstack([\n",
    "            self.data.reshape(-1, 1),  # (T, 1)\n",
    "            self.time_features         # (T, 7)\n",
    "        ]).astype(np.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of valid samples.\n",
    "        \n",
    "        Explanation:\n",
    "        - Need P steps for encoder input\n",
    "        - Need A steps for aging delay\n",
    "        - Need F steps for target output\n",
    "        Total: P + A + F - 1 steps minimum\n",
    "        \"\"\"\n",
    "        return len(self.features) - self.P - self.A - self.F + 2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single training sample.\n",
    "        \n",
    "        Returns:\n",
    "            encoder_input: (P, 8) - Historical CSI from t-P-A+1 to t-A\n",
    "            decoder_input: (G+F, 8) - G recent CSI + F zeros (for prediction)\n",
    "            target: (F, 8) - Ground truth CSI from t+1 to t+F\n",
    "        \"\"\"\n",
    "        # Encoder input: P historical steps ending at t-A\n",
    "        encoder_input = self.features[idx:idx+self.P]  # (P, 8)\n",
    "        \n",
    "        # Target: F future steps (from t-A+1 to t-A+F)\n",
    "        target = self.features[idx+self.P:idx+self.P+self.F]  # (F, 8)\n",
    "        \n",
    "        # Decoder input: G recent steps + F zeros\n",
    "        # Recent G steps: from t-G-A+1 to t-A\n",
    "        decoder_recent = self.features[idx+self.P-self.G:idx+self.P]  # (G, 8)\n",
    "        \n",
    "        # Create F zero steps for future prediction\n",
    "        decoder_zeros = np.zeros((self.F, 8), dtype=np.float32)\n",
    "        \n",
    "        # Concatenate: decoder_input has shape (G+F, 8)\n",
    "        decoder_input = np.vstack([decoder_recent, decoder_zeros])\n",
    "        \n",
    "        return (\n",
    "            torch.as_tensor(encoder_input, dtype=torch.float32),\n",
    "            torch.as_tensor(decoder_input, dtype=torch.float32),\n",
    "            torch.as_tensor(target, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDatasetFF(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        raw_data_in: Input channel measurements\n",
    "        raw_data_out: Output channel measurements\n",
    "        P, G, F, A: Same as TimeDataset\n",
    "        mean_in/std_in: Normalization for input\n",
    "        mean_out/std_out: Normalization for output\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 raw_data_in, raw_data_out,\n",
    "                 P, G, F, A,\n",
    "                 mean_in=None, std_in=None, \n",
    "                 mean_out=None, std_out=None,\n",
    "                 start_idx=None, end_idx=None):\n",
    "        self.P = int(P)\n",
    "        self.G = int(G)\n",
    "        self.F = int(F)\n",
    "        self.A = int(A)\n",
    "        \n",
    "        # Process input data\n",
    "        raw_data_in = raw_data_in.astype(np.float32)\n",
    "        self.raw_data_in = raw_data_in[start_idx:end_idx]\n",
    "        self.mean_in = mean_in if mean_in is not None else self.raw_data_in.mean()\n",
    "        self.std_in = std_in if std_in is not None else self.raw_data_in.std()\n",
    "        self.data_in = ((self.raw_data_in - self.mean_in) / (self.std_in + 1e-8)).astype(np.float32)\n",
    "        \n",
    "        # Process output data\n",
    "        raw_data_out = raw_data_out.astype(np.float32)\n",
    "        self.raw_data_out = raw_data_out[start_idx:end_idx]\n",
    "        self.mean_out = mean_out if mean_out is not None else self.raw_data_out.mean()\n",
    "        self.std_out = std_out if std_out is not None else self.raw_data_out.std()\n",
    "        self.data_out = ((self.raw_data_out - self.mean_out) / (self.std_out + 1e-8)).astype(np.float32)\n",
    "        \n",
    "        # Generate time features\n",
    "        self.time_features_in = generate_time_features(len(self.raw_data_in)).astype(np.float32)\n",
    "        self.time_features_out = generate_time_features(len(self.raw_data_out)).astype(np.float32)\n",
    "        \n",
    "        # Combine features\n",
    "        self.features_in = np.hstack([\n",
    "            self.data_in.reshape(-1, 1),\n",
    "            self.time_features_in\n",
    "        ]).astype(np.float32)\n",
    "        \n",
    "        self.features_out = np.hstack([\n",
    "            self.data_out.reshape(-1, 1),\n",
    "            self.time_features_out\n",
    "        ]).astype(np.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return min(len(self.features_in), len(self.features_out)) - self.P - self.A - self.F + 2\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get sample with separate input/output sources\"\"\"\n",
    "        # Encoder uses input features\n",
    "        encoder_input = self.features_in[idx:idx+self.P]\n",
    "        \n",
    "        # Decoder and target use output features\n",
    "        decoder_recent = self.features_out[idx+self.P-self.G:idx+self.P]\n",
    "        decoder_zeros = np.zeros((self.F, 8), dtype=np.float32)\n",
    "        decoder_input = np.vstack([decoder_recent, decoder_zeros])\n",
    "        \n",
    "        target = self.features_out[idx+self.P:idx+self.P+self.F]\n",
    "        \n",
    "        return (\n",
    "            torch.as_tensor(encoder_input, dtype=torch.float32),\n",
    "            torch.as_tensor(decoder_input, dtype=torch.float32),\n",
    "            torch.as_tensor(target, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard sinusoidal positional encoding from \"Attention is All You Need\".\n",
    "    \n",
    "    This encoding allows the model to utilise sequence order information.\n",
    "    Each position gets a unique encoding based on sine/cosine functions\n",
    "    at different frequencies.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        # Create positional encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        # Apply sin to even indices, cos to odd indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Add batch dimension: (1, max_len, d_model)\n",
    "        \n",
    "        # Register as buffer (not a parameter, but part of state)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Add positional encoding to input\n",
    "        \n",
    "        Args:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "        Returns:\n",
    "            x + positional_encoding: same shape as x\n",
    "        \"\"\"\n",
    "        return x + self.pe[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Single Transformer encoder block with:\n",
    "    1. Multi-head self-attention\n",
    "    2. Feed-forward network\n",
    "    3. Residual connections and layer normalization\n",
    "    \n",
    "    This follows the standard Transformer architecture from Vaswani et al.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, nhead, d_ff=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Multi-head attention (batch_first=True for easier handling)\n",
    "        self.self_attn = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, \n",
    "            num_heads=nhead, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass with residual connections\n",
    "        \n",
    "        Args:\n",
    "            x: (batch_size, seq_len, d_model)\n",
    "        Returns:\n",
    "            x: same shape, after attention and FFN\n",
    "        \"\"\"\n",
    "        # Self-attention with residual connection\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = x + self.dropout1(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # Feed-forward with residual connection\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + self.dropout2(ffn_out)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Transformer encoder with:\n",
    "    - Input projection (data_dim → d_model)\n",
    "    - Positional encoding\n",
    "    - Stack of encoder blocks\n",
    "    - Optional final normalisation\n",
    "    \"\"\"\n",
    "    def __init__(self, attn_layers, data_dim, d_model, norm_layer=None):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(data_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.norm = norm_layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Process input sequence through all encoder layers\n",
    "        \n",
    "        Args:\n",
    "            x: (batch_size, seq_len, data_dim)\n",
    "        Returns:\n",
    "            encoded: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = self.input_proj(x)       # Project to d_model\n",
    "        x = self.pos_encoder(x)      # Add positional encoding\n",
    "        \n",
    "        # Pass through all encoder blocks\n",
    "        for attn_layer in self.attn_layers:\n",
    "            x = attn_layer(x)\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz, device):\n",
    "    \"\"\"\n",
    "    \n",
    "    This mask ensures that position i can only attend to positions <= i,\n",
    "    maintaining the autoregressive property needed for sequential prediction.\n",
    "    \n",
    "    Args:\n",
    "        sz: Sequence length\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        mask: (sz, sz) with -inf in upper triangle, 0 elsewhere\n",
    "        \n",
    "    Example for sz=4:\n",
    "        [[0,    -inf, -inf, -inf],\n",
    "         [0,    0,    -inf, -inf],\n",
    "         [0,    0,    0,    -inf],\n",
    "         [0,    0,    0,    0   ]]\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(sz, sz, device=device) * float('-inf'), diagonal=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "class TransformerDecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    The decoder has three sub-layers:\n",
    "    1. Masked multi-head self-attention (with causal mask)\n",
    "    2. Cross-attention to encoder output\n",
    "    3. Feed-forward network\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, nhead, d_ff=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Masked self-attention\n",
    "        self.masked_attn = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        # 2. Cross-attention\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        # 3. Feed-forward\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, memory, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass with causal masking.\n",
    "        \n",
    "        Args:\n",
    "            x: (batch, tgt_len, d_model) - decoder input\n",
    "            memory: (batch, src_len, d_model) - encoder output\n",
    "            tgt_mask: (tgt_len, tgt_len) - causal mask\n",
    "        \n",
    "        Returns:\n",
    "            x: (batch, tgt_len, d_model) - decoder output\n",
    "        \"\"\"\n",
    "        # 1. Masked self-attention (with causal mask!)\n",
    "        _x, _ = self.masked_attn(x, x, x, attn_mask=tgt_mask)\n",
    "        x = self.norm1(x + self.dropout1(_x))\n",
    "        \n",
    "        # 2. Cross-attention with encoder\n",
    "        _x, _ = self.cross_attn(x, memory, memory)\n",
    "        x = self.norm2(x + self.dropout2(_x))\n",
    "        \n",
    "        # 3. Feed-forward\n",
    "        _x = self.ffn(x)\n",
    "        x = self.norm3(x + self.dropout3(_x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete decoder combining Transformer and LSTM.\n",
    "    \n",
    "    Architecture (as per paper):\n",
    "    - Transformer path: Processes decoder input with cross-attention to encoder\n",
    "    - LSTM path: Runs in parallel on the raw sequence values\n",
    "    - Concatenate both paths and use FC layer for final prediction\n",
    "    \n",
    "    This hybrid approach leverages:\n",
    "    - Transformer: Global dependencies, parallel processing\n",
    "    - LSTM: Local temporal patterns, sequential modeling\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, data_dim, d_model, lstm_dim, hidden_size=64, norm_layer=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Transformer components\n",
    "        self.input_proj = nn.Linear(data_dim, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        \n",
    "        # LSTM components (processes raw channel values)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_dim, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=2,  # Stack 2 LSTM layers\n",
    "            batch_first=True,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        \n",
    "        # Fusion: Combine Transformer and LSTM features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model + hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data, memory, original_seq):\n",
    "        \"\"\"\n",
    "        Forward pass through decoder\n",
    "        \n",
    "        Args:\n",
    "            data: (batch, G+F, data_dim) - decoder input with time features\n",
    "            memory: (batch, P, d_model) - encoder output\n",
    "            original_seq: (batch, G+F) - raw channel values for LSTM\n",
    "        \n",
    "        Returns:\n",
    "            out: (batch, G+F) - predicted channel values\n",
    "        \"\"\"\n",
    "        batch_size = data.size(0)\n",
    "        seq_len = data.size(1)\n",
    "        device = data.device\n",
    "        \n",
    "        # Generate causal mask\n",
    "        tgt_mask = generate_square_subsequent_mask(seq_len, device)\n",
    "        \n",
    "        # Transformer path\n",
    "        x = self.input_proj(data)       # (batch, G+F, d_model)\n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, tgt_mask)  # Use causal mask!\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        \n",
    "        # LSTM path (processes raw channel values)\n",
    "        lstm_out, _ = self.lstm(original_seq.unsqueeze(-1))  # (batch, G+F, hidden_size)\n",
    "        \n",
    "        # Combine Transformer and LSTM features\n",
    "        combined = torch.cat([x, lstm_out], dim=-1)  # (batch, G+F, d_model + hidden_size)\n",
    "        out = self.fc(combined)                      # (batch, G+F, 1)\n",
    "        out = out.squeeze(-1)                        # (batch, G+F)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(encoder, decoder, loader, device, F):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation/test set using NMSE metric.\n",
    "    \n",
    "    NMSE (Normalised Mean Squared Error) is used in the paper because\n",
    "    it's scale-invariant and better suited for channel prediction.\n",
    "    \n",
    "    Args:\n",
    "        encoder, decoder: Model components\n",
    "        loader: DataLoader\n",
    "        device: torch device\n",
    "        F: Number of future steps to predict\n",
    "    \n",
    "    Returns:\n",
    "        avg_loss: Average NMSE across all batches\n",
    "    \"\"\"\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for encoder_in, decoder_in, target in loader:\n",
    "            # Move to device\n",
    "            encoder_in = encoder_in.to(device)\n",
    "            decoder_in = decoder_in.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Extract original sequence for LSTM (first column = channel value)\n",
    "            original_seq = decoder_in[:, :, 0]  # (batch, G+F)\n",
    "            \n",
    "            # Forward pass\n",
    "            encoded = encoder(encoder_in)\n",
    "            pred = decoder(decoder_in, encoded, original_seq)\n",
    "            \n",
    "            # We only care about the last F predictions (future steps)\n",
    "            pred_future = pred[:, -F:]      # (batch, F)\n",
    "            target_vals = target[:, :, 0]   # (batch, F)\n",
    "            \n",
    "            # Compute NMSE per sample, then average\n",
    "            numerator = torch.sum((pred_future - target_vals) ** 2, dim=1)\n",
    "            denominator = torch.sum(target_vals ** 2, dim=1) + 1e-8\n",
    "            nmse = numerator / denominator\n",
    "            loss = torch.mean(nmse)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_early_stop(encoder, decoder, train_loader, val_loader, \n",
    "                          enc_opt, dec_opt, F, device, \n",
    "                          epochs=100, patience=20, min_delta=0.001,\n",
    "                          train_dataset=None):\n",
    "    \"\"\"\n",
    "    Train the T-LSTM model with early stopping\n",
    "    \n",
    "    Early stopping prevents overfitting by monitoring validation loss\n",
    "    and stopping when it stops improving\n",
    "    \n",
    "    Args:\n",
    "        encoder, decoder: Model components\n",
    "        train_loader, val_loader: DataLoaders\n",
    "        enc_opt, dec_opt: Optimizers\n",
    "        F: Number of future steps\n",
    "        device: torch device\n",
    "        epochs: Maximum training epochs\n",
    "        patience: Early stopping patience\n",
    "        min_delta: Minimum improvement to reset patience\n",
    "        train_dataset: For saving normalization stats\n",
    "    \n",
    "    Returns:\n",
    "        history: Dict with 'train' and 'val' loss curves\n",
    "    \"\"\"\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "    history = {'train': [], 'val': []}\n",
    "    best_model = None\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
    "    print(f\"Prediction horizon (F): {F} steps\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # ========== TRAINING PHASE ==========\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for encoder_in, decoder_in, target in train_loader:\n",
    "            # Move to device\n",
    "            encoder_in = encoder_in.to(device)\n",
    "            decoder_in = decoder_in.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # Extract original sequence for LSTM\n",
    "            original_seq = decoder_in[:, :, 0]\n",
    "            \n",
    "            # Zero gradients\n",
    "            enc_opt.zero_grad()\n",
    "            dec_opt.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            encoded = encoder(encoder_in)\n",
    "            pred = decoder(decoder_in, encoded, original_seq)\n",
    "            \n",
    "            # Compute loss on future predictions only\n",
    "            pred_future = pred[:, -F:]\n",
    "            target_vals = target[:, :, 0]\n",
    "            \n",
    "            # NMSE loss\n",
    "            numerator = torch.sum((pred_future - target_vals) ** 2, dim=1)\n",
    "            denominator = torch.sum(target_vals ** 2, dim=1) + 1e-8\n",
    "            nmse = numerator / denominator\n",
    "            loss = torch.mean(nmse)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping (prevents exploding gradients)\n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), 1.0)\n",
    "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), 1.0)\n",
    "            \n",
    "            # Update weights\n",
    "            enc_opt.step()\n",
    "            dec_opt.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # ========== VALIDATION PHASE ==========\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = evaluate_model(encoder, decoder, val_loader, device, F)\n",
    "        \n",
    "        # Record history\n",
    "        history['train'].append(avg_train_loss)\n",
    "        history['val'].append(avg_val_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1:03d}/{epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.6f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.6f} | \"\n",
    "              f\"EarlyStop: {counter}/{patience}\")\n",
    "        \n",
    "        # ========== EARLY STOPPING CHECK ==========\n",
    "        if avg_val_loss < best_loss - min_delta:\n",
    "            best_loss = avg_val_loss\n",
    "            counter = 0\n",
    "            # Save best model\n",
    "            best_model = {\n",
    "                'encoder': encoder.state_dict(),\n",
    "                'decoder': decoder.state_dict(),\n",
    "                'mean': train_dataset.mean if train_dataset else None,\n",
    "                'std': train_dataset.std if train_dataset else None\n",
    "            }\n",
    "            print(f\"  → New best model! Val loss: {best_loss:.6f}\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Memory cleanup\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Save final model\n",
    "    if best_model is not None:\n",
    "        torch.save(best_model, 'best_model.pth')\n",
    "        print(f\"\\nBest model saved with val loss: {best_loss:.6f}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(data, mean, std):\n",
    "    \"\"\"Denormalize data back to original scale\"\"\"\n",
    "    return data * std + mean\n",
    "\n",
    "\n",
    "def calculate_metrics(true, pred):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive evaluation metrics\n",
    "    \n",
    "    Metrics:\n",
    "    - MSE: Mean Squared Error\n",
    "    - RMSE: Root Mean Squared Error\n",
    "    - MAE: Mean Absolute Error\n",
    "    - R²: Coefficient of determination\n",
    "    - NMSE: Normalised MSE\n",
    "    \"\"\"\n",
    "    true = np.array(true, dtype=np.float32)\n",
    "    pred = np.array(pred, dtype=np.float32)\n",
    "    \n",
    "    mse = mean_squared_error(true, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    r2 = r2_score(true, pred)\n",
    "    \n",
    "    # NMSE\n",
    "    num = np.sum((pred - true) ** 2)\n",
    "    denom = np.sum(true ** 2) + 1e-8\n",
    "    nmse = num / denom\n",
    "    \n",
    "    print(f\"MSE:  {mse:.6f}\")\n",
    "    print(f\"RMSE: {rmse:.6f}\")\n",
    "    print(f\"MAE:  {mae:.6f}\")\n",
    "    print(f\"R²:   {r2:.6f}\")\n",
    "    print(f\"NMSE: {nmse:.6f}\")\n",
    "    print(f\"NMSE (dB): {10 * np.log10(nmse):.2f} dB\")\n",
    "    \n",
    "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'NMSE': nmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pipeline(model_path, test_dataset, data_dim, d_model, nhead, \n",
    "                 lstm_dim, hidden_size, F, device):\n",
    "    \"\"\"\n",
    "    Complete testing pipeline: load model, run inference, compute metrics\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to saved model\n",
    "        test_dataset: Test Dataset instance\n",
    "        data_dim, d_model, nhead, lstm_dim, hidden_size: Model hyperparameters\n",
    "        F: Prediction horizon\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        trues_denorm: Ground truth in original scale\n",
    "        preds_denorm: Predictions in original scale\n",
    "    \"\"\"\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    # Rebuild model architecture\n",
    "    attn_layers = [TransformerEncoderBlock(d_model=d_model, nhead=nhead) for _ in range(2)]\n",
    "    encoder = TransformerEncoder(\n",
    "        attn_layers=attn_layers,\n",
    "        data_dim=data_dim,\n",
    "        d_model=d_model,\n",
    "        norm_layer=nn.LayerNorm(d_model)\n",
    "    ).to(device)\n",
    "    \n",
    "    decoder_blocks = [TransformerDecoderBlock(d_model=d_model, nhead=nhead) for _ in range(2)]\n",
    "    decoder = Decoder(\n",
    "        decoder_blocks,\n",
    "        data_dim=data_dim,\n",
    "        d_model=d_model,\n",
    "        lstm_dim=lstm_dim,\n",
    "        hidden_size=hidden_size\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load weights\n",
    "    encoder.load_state_dict(checkpoint['encoder'])\n",
    "    decoder.load_state_dict(checkpoint['decoder'])\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    # Run inference\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for encoder_in, decoder_in, target in test_loader:\n",
    "            encoder_in = encoder_in.to(device)\n",
    "            decoder_in = decoder_in.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            original_seq = decoder_in[:, :, 0]\n",
    "            \n",
    "            encoded = encoder(encoder_in)\n",
    "            pred = decoder(decoder_in, encoded, original_seq)\n",
    "            \n",
    "            # Get future predictions\n",
    "            pred_future = pred[:, -F:].cpu().numpy()\n",
    "            target_vals = target[:, :, 0].cpu().numpy()\n",
    "            \n",
    "            all_preds.append(pred_future)\n",
    "            all_targets.append(target_vals)\n",
    "    \n",
    "    # Concatenate results\n",
    "    preds = np.concatenate(all_preds)  # (N, F)\n",
    "    trues = np.concatenate(all_targets)  # (N, F)\n",
    "    \n",
    "    # Denormalize\n",
    "    preds_denorm = inverse_normalize(preds, checkpoint['mean'], checkpoint['std'])\n",
    "    trues_denorm = inverse_normalize(trues, checkpoint['mean'], checkpoint['std'])\n",
    "    \n",
    "    return trues_denorm, preds_denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(true_values, pred_values, save_path='prediction_comparison.png'):\n",
    "    \"\"\"\n",
    "    Visualise prediction results.\n",
    "    \n",
    "    Args:\n",
    "        true_values: Ground truth array\n",
    "        pred_values: Prediction array\n",
    "        save_path: Where to save the plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot first 500 samples for clarity\n",
    "    plot_len = min(500, len(true_values))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(true_values[:plot_len], label='True', alpha=0.7, linewidth=1)\n",
    "    plt.plot(pred_values[:plot_len], label='Predicted', alpha=0.7, linewidth=1)\n",
    "    plt.title(\"Time Series Prediction Comparison\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Channel Value\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(true_values, pred_values, alpha=0.3, s=1)\n",
    "    plt.plot([true_values.min(), true_values.max()], \n",
    "             [true_values.min(), true_values.max()], \n",
    "             'r--', label='Perfect Prediction')\n",
    "    plt.title(\"Prediction Scatter Plot\")\n",
    "    plt.xlabel(\"True Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    print(f\"Plot saved to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
